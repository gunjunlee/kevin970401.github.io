---
layout: post
title: "AutoML(정리 안 됨)"
categories: DNN
author: lee gunjun
---

# AutoML
----

## AutoML 종류
----

1. Feature engineering
2. Model architecture
3. Hyperparameter
4. Etc (augmentation..)

### 1. Feature engineering
----

### 2. Model architecture
----

### 3. Hyperparameter
----

* Manual Search
    * 손으로 한땀한땀 찾아보는 것.
* Grid Search
    * Hyperparameter 가능한 경우의 수를 일정 룰(Grid)에 따라 만들어 놓고 test 한 뒤 좋은거 select
* Random Search
    * random 으로 넣어보고 좋은 거 select
* Bayesian Optimization
    * 이걸 알아보자.

#### Bayesian Optimization

현재까지 시행한  (hyperparameter, err) 결과를 이용하여 statistic model을 만들고, 그를 이용하여 다음 hyperparameter 선택. Manual, Grid, Random Search 와는 다르게 지금까지의 실험결과를 이용함. Bayesian optimization 을 이용하면 손쉽고, 빠르게 더 좋은 hyperparameter를 찾을 수 있다. 물론 그렇지 않은 경우도 있다.

사실 Bayesian optimization 잘 안쓰이는데 그 이유는 bayesian optimization에도 hyperparameter가 있고 그에 따라 성능 차이가 심하다

$$x^\star = arg\min_{x \in X}$$

Bayesian Optimization 은 위와 같은 optimization 문제를 푸는 methods 중 하나다.

**Surrogate Model, Acquisition Function** 이 핵심 요소.

1. Surrogate Model 은 현재까지 시행한 실험들의 결과를 이용하여 objective function 을 estimate 함.
2. Acquisition function은 objective function 을 더 잘 예측하는 데 도움을 가장 많이 줄 수 있는 지점. 즉 다음 실험 지점 x을 추천한다.
3. 이를 반복하여 실제 f을 정밀하게 예측

Surrogate Model 로는 DNN, Gaussian Process 등이 있다. 우리는 그중에서 먼저 Gaussian Process 를 이용해 볼 것이다.

**GP(Gaussian Process)** 에 대한 설명을 먼저 해보자.




### 4. Etc
----

#### Auto Augmentation

한 Policy 는 5개의 sub-policies 로 구성. 각 sub-policy 는 두개의 이미지 operations 로 구성되어 있음. 각 operation은 두 개의 파라미터를 가짐. 적용될 probability 와 적용했을 때의 강도 magnitude. 

search space 크기를 계산해보자. 논문에선 magnitude 를 10개, probability 를 11개 골라서 씀. prob랑 mag 후보를 continuous 하게 하지않고 discrete 하게 잡아놓음.

training 할 때 각각의 이미지는 다섯개의 sub-policy 중 하나가 랜덤으로 적용됨. 

총평: auto 라면서 manual 이 좀 심하다..

## Reference

* <http://research.sualab.com/introduction/practice/2019/02/19/bayesian-optimization-overview-1.html>
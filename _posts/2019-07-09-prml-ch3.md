---
layout: post
title: "PRML Ch.3 - linear models for regression"
categories: PRML
author: lee gunjun
---

무엇을 알아갈 것인가

1. regression 이란
2. mle 와 lsm
3. normal equation
4. moore penrose pseudo inverse matrix
5. sequential learning
6. l1, l2 regularizatoin
7. bias-variance decomposition

# Intro

지금까진 unsupervised learning 에 초점이 맞춰져있었다. 이제 supervised learning 에 대해 알아보자.

먼저 regression 문제에 대해 다뤄볼 것이다.

regression: N개의 observation $\lbrace x_n \rbrace$ 과 이에 해당하는 target $\lbrace t_n \rbrace$ 이 training set 으로 주어졌을 때 새 value x 에 대한 target t를 예측하는 것.

# 1. Linear basis function models

우리는 regression 문제를 linear 로 모델링할 것이다.

linear regression 은 다음과 같다

$$y(x, w) = w_0 + \sum_{j=1}^{M-1} w_j \phi_j(x)$$

여기서 $\phi(x)$ 는 basis function 이라 부른다. basis function 을 이용해도 모델은 parameter w 에 대해 선형 함수이기 때문에 쉽게 분석 가능하다

이 때 $\phi_0(x)=1$ 이라 하면 linear regression 은 다음과 같이 간단하게 표현할 수 있다.

$$y(x, w) = \sum_{j=0}^{M-1} w_j \phi_j(x)$$

참고로 basis function 으로는 gaussian basis function, sigmoid basis function, logistic basis function 등의 함수가 모두 가능하다

## 1.1 MLE 와 LSM

1장에서 Gaussian noise models 을 가정했을 때 mle을 쓰면 lsm 이 나오는 건 보였었다. 다시 이 논의로 돌아가서 mle 와 lsm 의 관계에 대해 더 자세히 알아보자.

이전과 동일한 가정에서 출발한다.

$$t = y(x, w) + \epsilon$$

$\epsilon$ 은 0을 평균, $\beta$를 정밀도로 가지는 Gaussian probability variable. 즉 아래와 같이 적을 수 있다.

$$p(t \vert x, w, \beta) = \mathcal{N}(t \vert y(x, w), \beta^{-1})$$

noise 분포가 가우시안이라는 가정은 당연히 몇몇 사례에선 적절하지 않다. 이에 대해서는 나중에 14장 쯤에서 다루니까 지금은 무시하자.

likelihood 는 다음과 같다

$$p(\mathbf{t} \vert \mathbf{x}, w, \beta) = \prod_{n=1}^N \mathcal{N} (t_n \vert w^T \phi(x_n), \beta^{-1})$$

log likelihood 를 구하면

$$\log p(\mathbf{t} \vert \mathbf{x}, w, \beta) = \sum_{n=1}^N \log \mathcal{N} (t_n \vert w^T \phi(x_n), \beta^{-1}) = \frac{N}{2} \log \beta - \frac{N}{2}\log(2\pi) - \frac{\beta}{2} \sum_{n=1}^N \{t_n - w^T \phi(x_n) \}^2$$

MLE 를 쓰면 LSM 이 나오는 것을 보였다.

MLE 를 적용하여 $w$ 와 $\beta$ 를 구할 수 있다.

$$w^{MLE} = (\Phi^T \Phi)^{-1} \Phi^T t$$

위의 식을 normal equation 이라 부른다. $\Phi$ 는 design matrix 라 부르고, $\Phi_{nj} = \phi_j(x_n)$

$(\Phi^T \Phi)^{-1} \Phi^T$ 는 Moore-Penrose pseudo-inverse 라고 한다.

$beta$ 의 MLE 값은 다음과 같다.

$$\frac{1}{\beta_{ML}} = \frac{1}{N} \sum_{n=1}^N \lbrace t_n - w_{ML}^T \phi (x_n) \rbrace^2$$

## 1.3 Sequential Learning

위와 같은 방법은 해를 구하기 위해 total training set 을 한번에 처리해야 한다. set이 작으면 괜찮지만 set 이 큰 경우 계산하기 너무 복잡하다는 문제가 발생한다. 이런 경우 sequential algorithm 을 사용하여 해결할 수 있다. online algorithm 이라고도 한다.

sequential learning(=online learning): 한번에 하나의 data point 고려하여 그때마다 parameter update

stochastic gradient descent 를 이용하여 sequential learning 구현이 가능함.

$w^{(\tau+1)} = w^{(\tau)} - \eta \nabla E_n$

## 1.4 Regularized least squares

overfitting 문제를 막기위해 regularization 항을 추가하는 아이디어에 대해 chapter 1 에서 소개했었다. regularization 를 포함하는 total error 는 다음과 같다.

$$E_D (w) + \lambda E_W(w)$$

우리는 대표적인 regularization 기법인 l2 regularization 과 l1 regularization 데 대해 다룰 것이다.

l2 regularization 은 weight decay, ridge 라고도 불리며 아래의 식과 같다.

$$E_W(w) = \frac{1}{2}w^T w$$

weight decay 를 사용하면 weight 가 0을 향해 축소된다. 이를 parameter shrinkage 라고 한다.

l1 regularization 은 lasso 라고도 불리며 아래와 같다

$$E_W(w) = \frac{\lambda}{2} \sum \left\vert w_j \right\vert$$

몇몇 weight 가 0이 되어 model 을 sparse 하게 만들어주는 효과가 있다.

## 1.5 Multiple outputs

지금까진 입력에 대한 출력의 차원이 1차원이었다. multiple outputs 은 출력의 차원을 K>1 로 두는 것이다. multiple outputs 는 뭐 별반 다를 거 없다. 간단하므로 생략한다.

# 2. bias-variance decomposition

$$\mathbb{E}_D \left[ \lbrace y(x ; D) - h(x) \rbrace^2 \right] = \lbrace \mathbb{E}_D \left[ y(x;D) \right] -h(x)\rbrace^2 + \mathbb{E}_D \left[ \lbrace y(x;D) - \mathbb{E}_D \left[ y(x;D) \right] \rbrace^2 \right]$$

즉 expected loss = bias$^2$ + var + noise

# 3. bayesian linear regression

앞서 다뤘듯이 MLE 를 사용하여 문제를 풀기 위해선 모델 복잡도를 결정하는 새로운 문제를 해결해야 한다. 그리고 모델끼리의 비교를 위해 validation set 이 필요하게 된다. 이러한 문제는 bayesian 방법론으로 해결할 수 있다. bayesian 을 사용하면 overfitting 문제를 해결할 수 있고 모델의 복잡도가 자동으로 결정되므로 validation set 또한 필요없다.

일단 문제를 간단하게 다루기 위해 target t를 1차원이라 가정한다.

remind: $p(t \vert x, w, \beta) = \mathcal{N}(t \vert y(x, w), \beta^{-1})$

## 3.1 parameter distribution

모델 매개변수에 대한 prior 를 도입하자. 아래와 같이 정규분포의 prior 를 도입한다.

$$p(w) = \mathcal{N} (w \vert m_0, S_0)$$

posterior 는 다음과 같이 나올 것이다.

$$p(w \vert t) = \mathcal{N}(w \vert m_N, S_N)$$

그냥 풀면 복잡하니 $m_0 = 0, S_0 = \alpha^{-1} I$ 라고 가정하자. 그러면

$$m_N = \beta S_N \Phi^T t$$

$$S_N^{-1} = \alpha I + \beta \Phi^T \Phi$$

을 얻을 수 있다. (이에 대한 유도 과정은 ch2 에서 이미 다 다뤘다.)

$w_{MAP}$ 는 당연히 $m_N$이다.

앞으로도 계속 문제를 쉽게 다루기 위해 $m_0 = 0, S_0 = \alpha^{-1} I$ 를 유지한다.

참고로 MAP 의 식 (likelihood*prior) 을 세우면 l2 regularization 이 나오는 것을 확인할 수 있다.

$$\log p(w \vert t) = -\frac{\beta}{2} \sum_{n=1}^N \lbrace t_n - w^T \phi (x_n)\rbrace^2 - \frac{\alpha}{2} w^T w + const$$

여기서 우리는 prior 와 posterior 가 같은 형태의 분포를 가지도록 하는 성질 (conjugacy) 를 만족시켰으므로 sequential update 가 가능하다.

![](/assets/images/prml2/linear_regression_bayesian.png)

## 3.2 prediction distribution

사실 실제 응용에는 w의 값을 알아내는 것보다 새로운 x 값에 대하여 t의 값을 predict 하는 것이 더 중요할 수 있다. 그러므로 predictive distribution $p(t \vert x, \mathbf{x}, \mathbf{t}, \alpha, \beta)$ 을 구해보자

$$p(t \vert x, \mathbf{x}, \mathbf{t}, \alpha, \beta) = \int p(t \vert x, w, \beta) p(w \vert \mathbf{x}, \mathbf{t}, \alpha, \beta)dw$$

이는 ch2 의 marginal probability 에서 이미 다룬 내용이다.

정리하면 $p(t \vert x, \mathbf{x}, \mathbf{t}, \alpha, \beta) = \mathcal{N}(t \vert m_N^T \phi(\mathbf{x}), \sigma_N^2(\mathbf{x})),\ \sigma_N^2(\mathbf{x}) = \frac{1}{\beta} + \phi(\mathbf{x})^T S_N \phi(\mathbf{x})$

분산의 첫번째 항은 noise 에 의한 분산을, 두번째 항은 w의 불확실성 내포한다.

## 3.3 Equivalent Kernel

prior 를 $p(w \vert \alpha)$ 로 잡았을 때의 posterior 의 MAP ($w_{MAP} = m_N = \beta S_N \Phi^T t$) 를 재밌게 해석할 수 있다. 이 해석은 kernel method 에 대해 알아보는 첫걸음이 될 것이다.

$w_{MAP}$ 를 linear regression 식에 대입하면 다음과 같다.

$$y(x, m_N) = m_N^T \phi(x) = \beta \phi(x)^T S_N \Phi^T \mathbf{t}$$

이는 다시 t에 대한 선형 결합으로 적을 수 있다.

$$y(x, m_N) = \sum_{n=1}^N k(x, x_n) t_n$$

여기서 $k(x, x_n)$ 는 $\beta\phi(x)^TS_N\phi(x_n)$ 이다. 그리고 이 $k(x, x_n)$는  equivalent kernel 이라 불린다. ($S_N$ 이 $x_n$ 에 대해 종속이므로 equiv kernel 은 $x_n$ 에 종속이다.)

즉 x 에 대한 prediction t 는 training set 의 target t 들의 weighted sum 으로 구해진다

kernel 답게 $\sum_{n=1}^N k(x, x_n)=1$ 의 성질도 만족한다.

# 4. bayesian model comparison

# 5. Evidence Approximation

# 6. Limitations of fixed basis functions

linear model 은 심각한 한계점이 있다. basis function 이 데이터를 관측하기 전에 고정되어 있으며 이에 따라 차원의 저주 문제를 야기한다는 것이다.

이를 극복하기 위해 Neural Network, SVM 와 같은 모델들을 추후 알아볼 것이다.

---
layout: post
title: "PRML Ch.3 - linear models for regression"
categories: PRML
author: lee gunjun
---

무엇을 알아갈 것인가

1. regression 이란
2. mle 와 lsm
3. normal equation
4. moore penrose pseudo inverse matrix
5. sequential learning
6. l1, l2 regularizatoin
7. bias-variance decomposition

regression: N개의 observation $\{x_n\}$ 과 이에 해당하는 target $\{t_n\}$ 이 training set 으로 주어졌을 때 새 value x 에 대한 target t를 예측하는 것.

linear regression: $y(x, w) = w_0 + \sum_{j=1}^{M-1} w_j \phi_j(x)$

basis function: $\phi(x)$

$\phi_0(x)=1$ 이라 하면

$y(x, w) = \sum_{j=0}^{M-1} w_j \phi_j(x)$

y(x, w) 는 x에 대해서는 nonlinear, w에 대해서는 linear 다. 그래서 linear regression 이라 불린다.

basis function 으로는 gaussian basis function, sigmoid basis function, logistic basis function 등이 있다.

mle 와 lsm

1장에서 Gaussian noise models 을 가정했을 때 mle을 쓰면 lsm 이 나오는 건 보였었다. 지금은 mle 와 lsm 의 관계에 대해 더 자세히 알아보자.

이전과 동일하게 $t = y(x, w) + \epsilon$, $\epsilon$ 은 0을 평균, $\beta$를 정밀도로 가지는 Gaussian probability variable.

즉 $p(t \vert x, w, \beta) = \mathcal{N}(t \vert y(x, w), \beta^{-1})$

noise 분포가 가우시안이라는 가정은 당연히 몇몇 사례에선 적절하지 않다. 이에 대해서는 나중에 14장 쯤에서 다루니까 지금은 무시하자.

likelihood: $p(t \vert x, w, \beta) = \prod_{n=1}^N \mathcal{N} (t_n \vert w^T \phi(x_n), \beta^{-1})$

log likelihood:   
$\log p(t \vert x, w, \beta) = \sum_{n=1}^N \log \mathcal{N} (t_n \vert w^T \phi(x_n), \beta^{-1}) = \frac{N}{2} \log \beta - \frac{N}{2}\log(2\pi) - \frac{\beta}{2} \sum_{n=1}^N \{t_n - w^T \phi(x_n) \}^2$

즉 mle 는 lsm 과 같다.~~(똑같은 얘기 또 함)~~

미분 해서 잘 풀어내면 $w^{MLE} = (\Phi^T \Phi)^{-1} \Phi^T t$. 이를 normal equation 이라 부른다. $\Phi$ 는 design matrix 라 부르고, $\Phi_{nj} = \phi_j(x_n)$

$(\Phi^T \Phi)^{-1} \Phi^T$ 는 Moore-Penrose pseudo-inverse 라고 한다.

위와 같이 하기 위해선 total training set 을 한번에 처리해야 한다. set 이 큰 경우 계산하기 너무 어려울 수 있다. 이런 경우 sequential algorithm 을 사용하는 방법이 있다. online algorithm 이라고도 한다.

sequential learning(=online learning): 한번에 하나의 data point 고려하여 그때마다 parameter update

stochastic gradient descent 를 이용하여 sequential learning 구현 가능함.

$w^{(\tau+1)} = w^{(\tau)} - \eta \nabla E_n$

----

overfitting 문제를 막기위해 regularization 쓴다.

regularization: $E_D (w) + \lambda E_W(w)$ 와 같은 형태를 띈다.

l2 regularization 과 l1 regularization 을 소개한다.

l2 regularization: $E_W(w) = \frac{1}{2}w^T w$

weight 가 0을 향해 축소됨. parameter shrinkage 라고 함. ridge

l1 regularization $E_W(w) = \frac{\lambda}{2} \sum \left\vert w_j \right\vert$

몇 weight 가 0이 됨. sparse model 이라함.

----

multiple outputs 는 뭐 별반 다를 거 없으니 생략

----

bias-variance decomposition

$\mathbb{E}_D \left[ \{ y(x ; D) - h(x) \}^2 \right] = \{ \mathbb{E}_D \left[ y(x;D) \right] -h(x)\}^2 + \mathbb{E}_D \left[ \{ y(x;D) - \mathbb{E}_D \left[ y(x;D) \right] \}^2 \right]$

expected loss = bias$^2$ + var + noise

----

bayesian linear regression

bayesian 으로 하면 val set 안 써도 됨.

mle 로 문제를 풀면 항상 overfitting 할것이다. 이를 bayesian 으로 풀면 해결할 수 있다.

prior: $p(w) = \mathcal{N} (w \vert m_0, S_0)$

then, posterior: $p(w \vert t) = \mathcal{N}(w \vert m_N, S_N)$

그냥 풀면 복잡하니 $m_0 = 0, S_0 = \alpha^{-1} I$ 라고 가정하자. then,

$m_N = \beta S_N \Phi^T t$

$S_N^{-1} = \alpha I + \beta \Phi^T \Phi$

$w^{MAP}$ 는 당연히 $m_N$이다.

이 상태($m_0 = 0, S_0 = \alpha^{-1} I$)에서 posterior 를 구하면 l2 regularization 이 나옴

----

bayesian 의 sequential update 방식에 대해 알아보자. 사후분포를 사전분포로 쓰는 것을 반복하면 된다. 여기서 사후분포와 사전분포는 가우시안으로 잡는다. 그림은 3.7 참조 -끝- 

----

사실 실제 응용에는 w의 값을 알아내는 것보다 새로운 x 값에 대하여 t의 값을 predict 하는 것이 더 중요할 수 있다. 그래서 predictive distribution 을 고려한다. 

$p(t \vert x, \mathbf{x}, \mathbf{t}, \alpha, \beta) = \int p(t \vert x, w, \beta) p(w \vert \mathbf{x}, \mathbf{t}, \alpha, \beta)dw$

정리하면 $p(t \vert x, \mathbf{x}, \mathbf{t}, \alpha, \beta) = \mathcal{N}(t \vert m_N^T \phi(\mathbf{x}), \sigma_N^2(\mathbf{x})),\ \sigma_N^2(\mathbf{x}) = \frac{1}{\beta} + \phi(\mathbf{x})^T S_N \phi(\mathbf{x})$

분산의 첫번째 항은 noise 에 의한 분산, 두번째 항은 w의 불확실성 내포.

----

Equivalent Kernel

prior 를 $p(w \vert \alpha)$ 로 잡았을 때의 posterior 의 MAP 를 재밌게 해석할 수 있다. 이 해석을 통해 kernel method 에 대해 알아볼 것이다.

prediction 은 $y(x, m_N) = m_N^T \phi(x) = \beta \phi(x)^T S_N \Phi^T \mathbf{t}$ 가 될것이다. 이를 t에 대한 선형 결합으로 적을 수 있다.

$$y(x, m_N) = \sum_{n=1}^N k(x, x_n) t_n$$

그러면 $k(x, x') = \beta\phi(x)^TS_N\phi(x')$ 이다. 이를 equivalent kernel 이라 부른다. 이는 $x_n$ 에 종속적이다.

----

여긴 나중에

<!-- bayesian model comparison

L 개의 모델 $\{M_i\},\ (i=1, \cdots, L)$ 들을 비교한다고 해보자.

$p(M_i \vert D) \propto p(M_i) p(D \vert M_i)$

생략.

----

The Evidence Approximation

완전한 bayesian 을 위해 $\alpha, \beta$ 에 대한 prior 를 도입하자. remind: $\alpha$는 w의 분산과, $\beta$는 x의 err의 분산과 관련있었다.

then, $p(t \vert \mathbf{t}) = \int \int \int p(t \vert w, \beta) p(w \vert t, \alpha, \beta) p(\alpha, \beta \vert t) dw d\alpha d\beta$
 -->



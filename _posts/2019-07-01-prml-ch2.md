---
layout: post
title: "PRML Ch.2 - probability distribution"
categories: PRML
author: lee gunjun
---

무엇을 알아갈 것인가

1. density estimation 이란
2. Bernoulli, mle
3. Binomial, mle
4. Binomial 의 prior
5. posterior 의 불확실성
6. Multinomial, mle
7. Multinomial 의 prior
8. Gaussian 과 Mahalanobis distance
9. Gaussian 의 mle
10. Gaussian 의 bayesian ($\sigma$ 고정, $\mu$ 고정, 고정x)
11. student-t 분포, mixture of gaussians
12. exponential family 의 형태
13. sigmoid 와 softmax
14. nonparametric method
15. histogram method
16. kernel 이란
17. kernel method
18. knn

# 1. Intro

density estimation: observed set $x_1, \cdots, x_n$ 이 주어졌을 때 $p(x)$ 을 모델링 하는 것.

우리는 이번 챕터에서 density estimation 을 다루는 몇가지 case 에 대해 알아볼 것이다. 이산 확률 변수는 binomial, multinomial distribution 로 알아보고 그 후 연속 확률 변수는 Gaussian distribution 를 이용하여 알아볼 것이다. 이들은 모두 작은 수의 parameter 들로 결정되는 parametric distribution 이다. (ex. gaussian 은 평균과 분산 두 파라미터로 결정됨.) 우리는 관찰된 데이터로 부터 적절한 paramter 값을 구할 것이다. 이에는 두가지 방법: frequentist, bayesian이 있는데, 두 경우 모두 다룰 것이다. frequentist 는 어떤 특정 기준을 최적화하는 매개변수를 찾는다. bayesian 은 데이터를 관측하기 전에 미리 매개변수의 사전분포를 가정하고, 관측된 데이터를 통해 사후분포를 계산한다.

bayesian 에서 conjugate prior probability 가 중요한 열쇠가 된다는 것도 알아볼 것이다. 이를 이용하면 사후 분포와 사전 분포가 같은 형태를 가질 수 있다.

parametric 방법에는 한계가 있다. 그중 한가지가 분포가 특정 함수의 형태를 띄고 있다는 가정한다는 것이다. 이는 많은 경우에 적절하지 않다. 이런 경우 nonparametric density estimation 을 쓰는 것이 대안이 될 수 있다. nonparametric density estimation 또한 parameter 들을 가질 수 있으나 이들은 분포의 형태를 결정짓는 게 아니라 모델의 복잡도에 영향을 끼친다. nonparametric density estimation 기법으로는 histogran, NN, kernel 등이 있다.

# 2. Binary Variables

앞으로 우린 관측된 dataset 을 $D = {x_1, \cdots, x_N}$ 이라 할 것이다.

Binary random variable $x \in \lbrace 0, 1 \rbrace$ 을 고려해보자. x=1 일 확률을 매개변수 $\mu$ 를 통해 다음과 같이 표현할 수 있다.

$$p(x=1 \vert \mu) = \mu$$

그러면 $p(x=0 \vert \mu) = 1-\mu$ 이고 이를 정리하면

$$Bern(x \vert \mu) = \mu^x(1-\mu)^{1-x} \text{, x}\in \lbrace 0,1 \rbrace$$

가 된다. 이를 Bernoulli distribution 이라 한다.

D 에 대해 likelihood 를 구해보면

$$p(D \vert \mu) = \prod_{n=1}^N \mu^x_n (1-\mu)^{1-x_n}$$

다시 이를 통해 D 에 대한 log-likelihood 를 구해보면

$$\log p(D \vert \mu) = \sum_{n=1}^N \lbrace x_n \log \mu + (1-x_n) \log (1-\mu) \rbrace$$

log-likelihood 를 최대로 만드는 $\mu$ 를 구하면

$$\mu^{MLE} = \frac{1}{N} \sum_{n=1}^N x_n$$

가 나온다.

위와 같이 동전을 한번 던졌을 때 그 값이 1일 확률을 구하는 것 말고도, N번 던졌을때 1이 n 번 나올 확률에 대해서도 생각해볼 수 있을 것이다. 이를 구해보면

$$Bin(m \vert N, \mu) = \binom{N}{m}\mu^m(1-\mu)^{N-m}$$

가 되는데, 이를 Binomial distribution 이라 한다.

앞에서 우린 MLE 를 이용하여 Bernoulli 의 매개변수 $\mu$ 에 대해 살펴봤다. 그런데 이 방법에는 문제점이 있다. N 이 작을 경우 과적합이 발생하기 쉽다는 점이다. 동전을 3번 던졌는데 우연찮게도 모두 앞면이 나왔다하자. 우리는 이를 통해 이 동전은 항상 앞면만 나오는 동전입니다 라고 말할 수 있을까? 제 아무리 frequentist 라 하더라도 저런 판단을 내리며 석연찮은 느낌을 받지 않을 수 없을 것이다. 우리는 이러한 과적합 문제를 Bayesian 적으로 접근하여 해결해 볼 것이다. 이를 위해선 매개변수 $\mu$ 의 사전분포 $p(\mu)$ 를 도입해야 한다.

여기서 prior 를 세울때 사용할 분포를 정하는 데에 꿀팁이 하나 있다. 바로 conjugate prior probability 를 이용하는 것!

bernoulli 에서 likelihood 가 $\mu^x_n (1-\mu)^{1-x_n}$의 형태를 가지고 있었다는 것에 주목하자. 만약 사전분포를 저런 형태를 가지는 함수를 선택한다면 우린 사후분포를 사전분포와 같은 형태로 만들 수 있을 것이다.

우리는 bernoulli 의 parameter $\mu$ 에 대한 prior distribution 으로 Beta 함수를 이용할 것이다.

$$Beta(\mu \vert a, b) = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\mu^{a-1}(1-\mu)^{b-1}$$

앞서 말했듯이 사전분포가 $\mu^{\dots} (1-\mu)^{\dots}$ 과 같은 형태임을 눈여겨 보며 뒤의 식 전개 과정을 보자.

$\mu$ 의 prior 를 beta 라 하고 bernoulli 의 likelihood 와 곱하면

$$p(\mu \vert m, N, a, b) \propto p(D \vert \mu) p(\mu) \propto \mu^{m+a-1} (1-\mu)^{N-m+b-1}$$

$$\therefore p(\mu \vert m, l, a, b) \sim Beta(\mu \vert m+a, l+b),\ l=N-m$$

prior 를 beta 로 잡았을때 posterior 또한 beta 가 됨을 확인할 수 있다. 이러한 성질을 conjugacy 라 한다.

위와 같은 상황처럼 사전 분포를 잘 모델링 하면 매 관찰마다 얻어낸 사후 분포를 그 다음 관찰에 대해 사전분포로 사용할 수 있다. 이렇게 매번 업데이트 하는 것이 bayesian 적 관점에서 자연스럽다. 이는 사전 분포나 가능도 함수의 선택과는 관련없이 데이터가 iid 이면 된다.  

더 많은 데이터를 관측할수록 posterior 의 불확실성 정도가 줄어들까? 즉 다시말해 posterior 의 분산이 줄어들까?

$$\begin{matrix}
var_D\left[\mathbb{E}_\theta \left[ \theta \vert D \right] \right] &=& \mathbb{E}_D \left[\mathbb{E}_\theta\left[\theta \vert D\right]^2\right] - \mathbb{E}_D \left[\mathbb{E}_\theta\left[\theta \vert D\right]\right]^2\\
&=&\mathbb{E}_D \left[\mathbb{E}_\theta\left[\theta \vert D\right]^2\right] - \mathbb{E}_\theta\left[\theta\right]^2\\
&=&\mathbb{E}_D \left[\mathbb{E}_\theta\left[\theta \vert D\right]^2\right] + var_\theta\left[\theta\right] -\mathbb{E}_\theta\left[\theta^2\right]\\
&=&\mathbb{E}_D \left[\mathbb{E}_\theta\left[\theta \vert D\right]^2\right] + var_\theta\left[\theta\right] -\mathbb{E}_D\left[\mathbb{E}_\theta\left[\theta^2 \vert D\right]\right]\\
&=& -\mathbb{E}_D\left[var_\theta\left[\theta \vert D\right]\right] + var_\theta\left[\theta\right]
\end{matrix}$$

사후 평균의 분산은 사전 분산 - 사후 분산의 평균으로 나타내어진다. 즉 분산이 줄어든다! 물론 여기서 본건 사후 *평균*의 분산이므로 어쩔땐 커지기도 한다.

# 2. Multinomial Variables

위에서는 binomial 의 경우를 살펴봤다. multinomial 에 대해서도 다뤄보자. 

$$Mult(m_1, \cdots, m_K \vert \mu, N) = \binom{N}{m_1 \cdots m_K}\prod_{k=1}^K\mu_k^{m_n}$$

$$\sum_{k=1}^K m_k=N$$

likelihood 를 구해보면 

$$p(D \vert \mu) = \prod_{n=1}^N \prod_{k=1}^K \mu_k^{x_{nk}} = \prod_{k=1}^K \mu_k^{\sum_n x_{nk}} = \prod_{k=1}^K \mu_k^{m_k}$$

MLE 를 이용하여 $\mu_k$ 를 구해보면 (라그랑주 승수법을 이용하면 된다)

$$\mu_k = \frac{m_k}{N}$$

을 구할 수 있다.

Multinomial 또한 bayesian 으로 풀어볼 수 있다.

conjugacy 를 위해 사전분포로 다음과 같이 잡아보자.

$$p(\mu \vert \alpha) \propto \prod_{k=1}^K \mu_k^{\alpha_k - 1}$$

normalize 하면 디리클레 분포가 나온다.

$$Dir(\mu \vert \alpha) = \frac{\Gamma(\alpha_0)}{\Gamma(\alpha_1) \cdots \Gamma(\alpha_K)} \prod_{k=1}^K \mu_k^{\alpha_k - 1}$$

$$\alpha_0 = \sum_{k=1}^K \alpha_k$$

prior로 dirichlet 를 사용한다 하자. 여기에 likelihood 를 곱하면 사후분포가 다음과 같이 구해진다.  

$$p(\mu \vert D, \alpha) \propto p(D \vert \mu) p(\mu \vert \alpha) \propto \prod_{k=1}^K \mu_k^{\alpha_k + m_k - 1}$$

우리가 원하는 대로 사후 분포 또한 dirichlet 분포로 나오는 것을 확인할 수 있다. 위 식을 normalize 하면 다음과 같은 식이 얻어진다.  
$p(\mu \vert D, \alpha) = Dir(\mu \vert \alpha+m)$

# 3. The Gaussian Distribution (Continuous Variable)

지금까진 discrete 변수를 모델링했다. 지금부터는 연속 변수를 모델링 해볼 것인데 연속 변수를 모델링 하는 데에는 Gaussian distribution 이 널리 활용된다.

1 차원 변수 x 에 대한 Gaussian 은 다음과 같다.

$$\mathcal{N}(x \vert \mu, \sigma^2) = \frac{1}{(2 \pi \sigma^2)^{1/2}}\exp\{- \frac{1}{2\sigma^2}(x-\mu)^2\}$$

D-dim Gaussian 은 다음과 같다.

$$\mathcal{N}(x \vert \mu, \Sigma) = \frac{1}{(2\pi)^{D/2} \left\vert \Sigma \right\vert^{1/2}} \exp\{-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)\}$$

참고로 gaussian 은 중요한 해석적 성질을 많이 가지고 있다.

첫째로 기하학적 성질에 대해 알아보자

Mahalanobis distance:

$$\Delta^2 = (x-\mu)^T \Sigma^{-1} (x-\mu)$$

$\Sigma^{-1}={\Sigma^{-1}}^{sym} + {\Sigma^{-1}}^{antisym}$로 나누면 Mahaloanobis distance 에서 ${\Sigma^{-1}}^{antisym}$ 은 사라지므로 generality 을 잃지 않고 우리는 $\Sigma^{-1}$ 가 대칭행렬이라 할 수 있다. $\Sigma^{-1}$ 가 대칭행렬이면 $\Sigma$ 또한 대칭행렬이므로, 최종적으로 $\Sigma$ 을 대칭행렬이라 할 것이다.

$\Sigma$ 가 실수 대칭 행렬이면 고유값 또한 실수다. 정규 직교 집합을 이루도록 고유 벡터를 선택하면 

$$u_i^Tu_j=I_{ij}$$

$$\Sigma = \sum_{i=1}^D \lambda_i u_i u_u^T$$

$$\Sigma^{-1} = \sum_{i=1}^D \frac{1}{\lambda_i}u_iu_i^T$$

이를 mahalanobis distance 에 적용하면 

$$\Delta^2 = \sum_{i=1}^D \frac{y_i^2}{\lambda_i},\ y_i = u_i^T (x-\mu)$$

즉 새로운 좌표 $Y=U(x-\mu)$ 가 나오고, 여기서 일정 비례씩 곱한다음 거리를 재는 것과 같다.

식으로 보면 이해가 잘 안되지만 그림을보면 이해하기 쉽다. 

![](/assets/images/prml2/mahalanobis_visualize.png)

이차 모멘트: $\mathbb{E}[xx^T] = \mu\mu^T+\Sigma$

covariance 는 아래와 같다.

$$cov[x]=\Sigma$$

gaussian 의 한계점은 gaussian 이 unimodal 이기 때문에 multimodal 에 대해 적절한 근사를 할 수 없다는 것이다.

## 3.1 conditional gaussian

$x \sim \mathcal{N}(x \vert \mu, \Sigma)$ 이고 $x = \binom{x_a}{x_b}$ 이며 그 평균값이 $\mu=\binom{\mu_a}{\mu_b}$ 라 하자. 

공분산 행렬 $\Sigma=\begin{pmatrix}\Sigma_{aa} & \Sigma_{ab} \\ \Sigma_{ba} & \Sigma_{bb} \end{pmatrix}$ 가 되고, 공분산행렬은 대칭이라 할 수 있으므로 $\Sigma_{aa}$와 $\Sigma_{bb}$는 대칭행렬이고 $\Sigma_{ba}^T = \Sigma_{ab}$ 이다. 

흔히 $\Sigma^{-1}$ 는 $\Lambda$ 로 쓰고 이를 precision matrix 라 부른다. 이 또한 대칭행렬이므로 $\Lambda=\begin{pmatrix}\Lambda_{aa} & \Lambda_{ab} \\ \Lambda_{ba} & \Lambda_{bb} \end{pmatrix}$ 이면 $\Lambda_{aa}$와 $\Lambda_{bb}$는 대칭행렬이고 $\Lambda_{ba}^T = \Lambda_{ab}$ 이다. (이 때 주의해야 할 점은 $\Sigma_{aa}^{-1}=\Lambda_{aa}$ 는 항상 성립되지 않는다)

$p(x_a \vert x_b)$ 에 대한 표현식을 찾아보자. 이는 $x_b$ 를 고정시키고 $x_a$ 의 확률 분포를 찾아내면 될 것이다.

$$\begin{matrix}
-\frac{1}{2} (x-\mu)^T \Sigma^{-1} (x-\mu) &=& -\frac{1}{2} (x_a-\mu)^T \Lambda_{aa} (x_a-\mu) \\
&&-\frac{1}{2} (x_a-\mu)^T \Lambda_{ab} (x_b-\mu)\\
&&-\frac{1}{2} (x_b-\mu)^T \Lambda_{ba} (x_a-\mu)\\
&&-\frac{1}{2} (x_b-\mu)^T \Lambda_{bb} (x_b-\mu)\\
\end{matrix}$$

normalize 하면 $x_a$ 에 관란 항만 남을 것이다. $x_a$ 에해 이 결과값은 다시 이차식의 형태임을 확인 할 수 있다. 따라서 $p(x_a \vert x_b)$ 는 gaussian 분포가 된다.

여기서 꿀팁 **completing the square**: Gaussian 의 지수상의 이차식이 주어졌을때 이로부터 평균과 공분산을 찾아내는 작업

$$-\frac{1}{2} x^T \Sigma^{-1} x + x^T \Sigma^{-1} \mu + const$$

와 같은 꼴로 만들면 $\Sigma$ 가 공분산, $\mu$ 가 평균이 된다.

이를 $p(x_a \vert x_b)$ 에 적용해보면.

$$\Sigma_{a \vert b}=\Lambda_{aa}^{-1}$$

$$\mu_{a \vert b} = \mu_a - \Lambda_{aa}^{-1} \Lambda_{ab} (x_b - \mu_b)$$

를 얻을 수 있다.

여기서 주목할 점은 평균이 $x_b$ 에 대해 linear 하다는 점이다.

## 3.2 Marginal Gaussian

앞서 우리는 $p(x_a, x_b)$ 가 Gaussian 이면 그의 Conditional $p(x_a \vert x_b)$ 도 Gaussian 임을 확인했다.

이때 Marginal $p(x_a)$ 도 Gaussian 일까?

$$p(x_a) = \int p(x_a, x_b) dx_b$$

위의 식을 이용하여 구할 것이다.

중간과정은 꽤 복잡하므로 생략한다. 시간만 많이 투자한다면 할 수 있을 것이다.

결과는 아래와 같다.

$$\mathbb{E}[x_a] = \mu_a$$

$$cov[x_a] = \Sigma_{aa}$$

![](/assets/images/prml2/marginal_gaussian.png)

## 3.3 Gaussian 에서 Bayes Theorem 

(bayesian inference 는 3.6 에서 함. 지금은 bayes theorem 적용만 함..)

지금 우리의 목표는 $p(x)$ 와 $p(y \vert x)$ 를 이용하여 $p(y)$ 와 $p(x \vert y)$ 를 구하는 것이다.

앞서 우리는 조건부 분포의 평균이 $x_b$ 에 대한 일차식임을 확인했었다. 이외에 조건부 분포의 공분산, marginal 의 평균, 공분산은 모두 $\Sigma$ 에 의해 결정됐다.

따라서 우리는 다음과 같이 정의한다.

$$p(x) = \mathcal{N} (x \vert \mu, \Lambda^{-1})$$

$$p(y \vert x) = \mathcal{N} (y \vert Ax + b, L^{-1})$$

($y$ 가 이전의 $x_a$, $x$ 가 이전의 $x_b$ 라 생각하면 된다)

우선 x, y 의 결합분포에 대한 표현식을 찾아보자. 이를 위해 $z=\binom{x}{y}$ 를 가정한다.

$$\begin{matrix}
\log p(z) &=& \log p(x) + \log p(y \vert x) \\ 
&=& -\frac{1}{2} (x-\mu)^T \Lambda (x-\mu)\\
&& -\frac{1}{2} (y-Ax-b)^T L (y-Ax-b) + const
\end{matrix}$$

위 식의 이차식을 이용하여 z 에 대한 정밀 행렬 R 을 구할 수 있다.

$$=-\frac{1}{2} \binom{x}{y}^T \begin{pmatrix} \Lambda+A^T L A & -A^T L \\ -LA & L \end{pmatrix} \binom{x}{y}$$

$$\therefore R = \begin{pmatrix} \Lambda+A^T L A & -A^T L \\ -LA & L \end{pmatrix}$$

아까 그 식의 일차식을 이용하면 z의 평균을 구할 수 있다.

$$\mathbb{E}[z] = \binom{\mu}{A\mu + b}$$

이제 x 에 대해 marginalize 하면 p(y) 에 대한 표현식을 구할 수 있다. 이는 앞에서 했으므로 그 결과를 가져다 쓰고 정리하면 

$$\mathbb{E} [y] = A \mu + b$$

$$cov[y] = L^{-1} + A \Lambda^{-1} A^T$$

이렇게 marginal distribution $p(y)$ 를 구했다.

마지막으로 conditional distribution $p(x \vert y)$ 에 대한 표현식을 구해보자. 이는 앞에서 이미 했으므로 (joint, marginal 이용하여 conditional 계산) 대입하고 정리하면 

$$\mathbb{E} [x \vert y] = (\Lambda + A^T L A)^{-1} \lbrace A^T L (y-b ) \Lambda \mu \rbrace$$

$$cov [x \vert y] = (\Lambda + A^T L A)^{-1}$$

을 얻을 수 있다.

지금까지 한 과정들은 bayes theorem 의 예시에 해당한다.

## 3.4 Gaussian 에서 MLE

$$\log p(X \vert \mu, \Sigma) = - \frac{ND}{2}\log(2 \pi) - \frac{N}{2} \log \left\vert \Sigma \right\vert - \frac{1}{2} \sum_{n=1}^N(x_n - \mu)^T\Sigma^{-1}(x_n - \mu)$$

log likelihood 가 위와 같이 구해진다. 여기서 최대가능도를 이용ㅎ면

$$\mu^{MLE} = \frac{1}{N}\sum_{n=1}^{N}x_n$$

$$\Sigma^{MLE} = \frac{1}{N}\sum_{n=1}^N (x_n - \mu^{MLE})(x_n - \mu^{MLE})^T$$

그리고 이들의 expectation 을 구해보면 

$$\mathbb{E}[\mu^{MLE}] = \mu$$

$$\mathbb{E}[\Sigma^{MLE}] = \frac{N-1}{N}\Sigma$$

$\Sigma^{MLE}$ 는 biased estimator 임을 알 수 있다. 

이는 아래와 같은 unbiased estimator 를 이용하여 해결할 수 있다.

$$\tilde{\Sigma}^{MLE} = \frac{1}{N-1}\sum_{n=1}^N (x_n - \mu^{MLE})(x_n - \mu^{MLE})^T$$

## 3.5 Sequential estimation

3.4 에서 했던 mle 에 대한 논의를 바탕으로 sequential estimation 에 대해 알아보자. sequential estimation 은 data point 들을 하나씩 처리하고 바로 버릴 수 있게 해준다. 따라서 이는 online application 에 중요하다.

$$\begin{matrix}
\mu_{ML}^{(N)}&=&\frac{1}{N} \sum_{n=1}^N x_n \\
&=& \frac{1}{N} x_N + \frac{1}{N} \sum_{n=1}^{N-1} x_n \\
&=& \frac{1}{N} x_N + \frac{N-1}{N} \mu_{ML}^{(N-1)}
\end{matrix}$$

위처럼 가장 최근의 estimator 와 data point 만을 가지고 sequential 하게 update 할 수 있다.

## 3.6 Gaussian 에서 bayesian Inference

remind

$$\mathcal{N} (\mu, \sigma^2) = \frac{1}{\sqrt{2\pi} \sigma} \exp \left( -\frac{(x-\mu)^2}{2\sigma^2} \right)$$

$$\mathcal{N} (\mu, \Sigma) = \frac{1}{(2\pi)^{N/2} det(\Sigma)^{1/2}} \exp \lbrace -\frac{1}{2} (x-\mu)^T \Sigma^{-1} (x-\mu) \rbrace$$

### 3.6.1 $\mu$ 를 추정. $\sigma$ 는 알고있다고 가정

N개의 observation $x=\lbrace x_1, \dots, x_N \rbrace$ 이 주어졌을 때 likelihood 는 다음과 같다.

 $p(x \vert \mu) = \prod_{n=1}^N p(x_n \vert \mu) = \frac{1}{(2\pi\sigma^2)^{N/2}} \exp \lbrace -\frac{1}{2\sigma^2}\sum_{n=1}^N (x_n - \mu)^2 \rbrace$

likelihood 가 이차식의 지수 형태므로 prior 로 gaussian 잡으면 posterior 도 gaussian 이 나올것이다.

prior 아래와 같이 잡자 

$$p(\mu) = \mathcal{N} (\mu \vert \mu_0, \sigma^2_0)$$

posterior 를 계산하면 아래와 같은 결과를 얻을 수 있다.

$$p(\mu \vert x) = \mathcal{N} (\mu \vert \mu_N, \sigma^2_N)$$

$$\mu_N = \frac{\sigma^2}{N \sigma_0^2 + \sigma^2}\mu_0 + \frac{N \sigma^2_0}{N \sigma_0^2 + \sigma^2}\mu^{MLE},\ \mu^{MLE}=\frac{1}{N} \sum_{n=1}^N x_n$$

$$\frac{1}{\sigma_N^2} = \frac{1}{\sigma_0^2}+\frac{N}{\sigma^2}$$

### 3.6.2 $\sigma(=1/\lambda)$ 를 추정. $\mu$ 는 알고있다고 가정

likelihood 는 아래와 같다

$$p(x \vert \lambda) = \prod_{n=1}^N p(x_n \vert \lambda) \sim \lambda^{N/2} \exp \{ -\frac{\lambda}{2}\sum_{n=1}^N (x_n - \mu)^2 \}$$

이는 $\lambda$의 거듭제곱과 선형 지수함수를 곱한 형태이므로 prior 로 감마함수를 쓰면 될 것이다.

$$p(\lambda) \sim Gamma(\lambda \vert a_0, b_0) = \frac{1}{\Gamma(a_0)}{b_0}^{a_0} \lambda^{a_0-1} \exp (-b_0 \lambda)$$

posterior 는 다음과 같이 구해진다.

$$p(\lambda \vert X) = \lambda^{a_0-1} \lambda^{N/2} \exp{-b_0\lambda - \frac{\lambda}{2}\sum_{n=1}^N (x_n - \mu)^2} \sim Gamma(\lambda \vert a_N, b_N)$$

$$a_N = a_0 + \frac{N}{2}, b_N = b_0 + \frac{1}{2} \sum_{n=1}^N (x_n - \mu)^2 = b_0 + \frac{N}{2} {\sigma^{MLE}}^2$$

### 3.6.3 $\mu$, $\sigma$ 를 추정.

이제 평균과 분산 둘 다 모른다고 해보자.

likelihood 는 아래와 같다.

$$p(X \vert \mu, \lambda) = \prod_{n=1}^N \left( \frac{\lambda}{2 \pi} \right)^{1/2} \exp \{ -\frac{\lambda}{2}(x_n - \mu)^2 \}$$

prior 로 Gaussian Gamma 분포를 쓰면 된다. 복잡하니 생략함. 

![](/assets/images/prml2/gaussian_gamma.png)

위와 같은 결과가 나온다.

### 3.6.4 다변량에서 $\mu$, $\sigma$ 를 추정.

다변량에서는 Wishart 분포를 사용함. 복잡하니 생략

## 3.7 student-t 분포

방금 전에 Gaussian 의 conjugate prior probability 로 Gamma 를 잡았었다. $p(x \vert \mu, \tau^-1)$, $p(\tau) = Gam(\tau \vert a, b)$. 이를 이용하여 x에 대한 marginal 을 구할 수 있다.

$$p(x \vert \mu, a, b) = \int_0^{\infty} \mathcal{N}(x \vert \mu, \tau^{-1})Gamma(\tau \vert a, b) d\tau = \frac{\Gamma(b/2 + 1/2)}{\Gamma(b/2)}\left( \frac{a}{\pi b} \right)^{1/2} \left[ 1+\frac{a(x-\mu)^2}{b} \right]^{-b/2-1/2}$$

이 결과값은 student-t distribution 과 같다. 즉 student-t 분포는 다른 정밀도를 가지는 무한히 많은 가우시안을 합함으로써 구할 수 있다. 즉 이는 무한한 mixture of Gaussians 이다. 

t 분포 특징은 Gaussian 대비 더 긴 꼬리를 가진다는 것이다. 이 덕분에 outlier 에 robust 하다는 장점을 가지게 된다.

![](/assets/images/prml2/student-t_robust.png)

t 분포의 MLE 해는 EM 알고리즘을 통해 구할 수 있다.

t 분포를 이용하여 regression 문제를 모델링할 수 있다. 이 때는 최소 제곱법을 사용하지 않는다. 최소제곱법은 가우시안 분포 하에서의 MLE 와 연관되어있기 때문이다.

## 3.8 periodic Variables 

생략

## 3.9 Mixture of Gaussians

Gaussian 을 혼합하면 mixture of gaussians 이 된다. $p(x) = \sum_{k=1}^K \pi_k \mathcal{N}(x \vert \mu_k, \Sigma_k)$ 당연히 $\sum \pi_k = 1$

어떤 임의의 분포도 충분히 많은 수의 Gaussian 분포를 사용한다면 임의의 정확도로 근사하는 것이 가능하다.

여기서 $\pi$ 를 $\pi_k = p(k)$ 즉 k 번째 성분을 뽑을 확률로 보면 $p(x) = \sum p(k) p(x\vert k)$ 가 됨. "Gaussians 들 중에서 하나를 고를 확률 * 그 가우시안에서 x가 나올 확률" 들의 합이 되고, $p(k \vert x)$ 를 responsibilities 라 한다.

$\pi_k=p(k)$ 는 k 번째 성분을 뽑을 prior probability 로 볼 수 있고, $\mathcal{N}(x \vert \mu_k, \Sigma_k) = p(x \vert k)$ 를 k 가 주어졌을때 x 의 확률로 볼 수 있다.

log likelihood 는 다음과 같다.

$$\log p(X \vert \pi, \mu, \Sigma) = \sum_{n=1}^N \log{\sum_{k=1}^K \pi_k \mathcal{N}(x_n \vert \mu_k, \Sigma_k)}$$

이 식은 mle 를 이전에 했던 것처럼 쉽게 구할 수가 없다. 이럴때 쓰는 방법으로 numerical optimization 혹은 EM(expectation maximum) 이 있다. EM은 9장에서 열심히 배울 것이다. numerical optimization 은 안 배운다. 즉 우린 최소 9장까진 할수있는게 없다. 따라서 지금은 여기서 마친다.

# 4. Exponential family

2장에서 지금까지 본 모든 분포는 (mixture of gaussians 빼고) 모두 exponential family 에 속한다.
 
exponential family 는 다음과 같이 정의된다.

$$p(x \vert \eta) = h(x)g(\eta)\exp{\eta^T u(x)}$$

각 분포들을 저 형태로 만들어보는 연습을 해보자.

*Bernoulli*

$Bern(x \vert \mu) = \mu^x (1-\mu)^{1-x} = (1-\mu) \exp\{ \log(\frac{\mu}{1-\mu})x \}$

여기서 $\eta = \log(\frac{\mu}{1-\mu})$ 인데 이를 $\mu$ 로 정리하면

$\mu = \sigma(\mu) = \frac{1}{1+\exp(-\eta)}$ : sigmoid

*Multinoulli*

$Multi(x \vert \mu) = \prod_{k=1}^K \mu_k^{x_k} = \exp \{ \sum x_k \log \mu_k \}$

여기서 $\eta_k = \log \mu_k$ 이고, 정리하면 $\mu_k = \frac{\exp(\eta_k)}{1+\sum \exp(\eta_j)}$ : softmax

*gaussian*

별 거 없으니 생략

sufficient statistic: mle 의 estimate 계산에 쓰이는 statistic. 얘들만 가지고 있으면 mle 를 할 수 있다. 예를 들어 Bernoulli 의 mle 에는 $\mu^{MLE} = \frac{1}{N} \sum_i x_i$. 즉 x의 각 값을 저장할 필요 없이 누적들만 저장하고 있으면 된다. 따라서 sufficient statistic 은 $\sum_i x_i$ 이다.

## 4.3 noninformative prior

prior 에서 어떤 점이 p(x) = 0 이면 사후 분포에서도 p(x) = 0 이 된다. 사전분포에 대해 아무런 정보가 없는데 저런 prior 를 사용했다간 잘못된 결과가 나오기 쉽다. 사전분포에 대한 아무런 정보가 없으면 어떡할까? discrete 변수의 경우 1/k 로 주는 방법이 있다. 

# 5. non-parametric method

parameter 가 없는 밀도추정방법이다.

## 5.1 histogram method

x 를 너비 $\Delta_i$ 를 가진 distinct bins 로 나누고 각 구간 i 에 속한 x 의 숫자 $n_i$ 를 세는 것이다.

$p_i = \frac{n_i}{N \Delta_i}$

histogram method 의 문제점은 각 bins 의 가장자리에 불연속면이 생긴다는 점이다. 또다른 문제점으론 고차원의 입력에서 각 차원마다 M개의 구간을 만들면 기하급수적으로 구간의 갯수가 커진다는 점이다.

대신 histogram 방법론에는 중요한 시사점이 있다. 

특정 위치의 probability density 를 estimate 하기 위해 local neighborhood 을 고려했다는 점이다.

그리고 구간의 갯수, 크기가 너무 커서도 작아서도 안된다는 점이다.

높은 차수에서 적용 가능한 Nonparametric method 로 kernel estimator 와 nearest neighbor 방법이 있다.

## 5.2 K-NN 과 kernel density estimators

구역 $\mathcal{R}$ 에서 probability mass 를 구해보자.

$$P = \int_\mathcal{R} p(x)dx$$

V 를 R의 부피라 하자. 그리고 문제 정의를 input x가 R에 속하냐 속하지 않냐의 문제로 보면 binomial 이 되고, N번 뽑아서 K 번 뽑혔다고 하면 다음과 같은 density estimator 를 얻을 수 있다. 

$$p(x) = \frac{K}{NV}$$

위 식을 두가지 방법으로 활용할 수 있다. K 을 고정하고 V 의 값을 데이터로부터 구하면 KNN, V을 고정시키고 데이터로부터 K 을 구하면 Kernel based method 가 된다.

### 5.2.1 kernel density estimator

우리가 확률밀도 p(x)를 구하고 싶은 x가 있고, x 주변의 작은 hypercube R 이 있다. 다음과 같은 함수를 이용하여 구역 R에 속하는 points 의 수 K 를 세자 

$$k(u) = \begin{cases} 1 & \vert u_i \vert \le 1/2, i=1,\cdots,D \\ 0 & otherwise \end{cases}$$

k(u) 는 kernel function 중 하나이다. k(u) 를 이용하면 x 를 중심으로 한변의 길이가 h 인 cube 안에 point y 가 들어가는 경우를 k((x-y)/h) 로 쓸 수 있다.

즉 $K = \sum_{n=1}^N k(\frac{x-x_n}{h})$

$\therefore p(x) = \frac{1}{N} \sum_{n=1}^N \frac{1}{h^D} k(\frac{x-x_n}{h})$

k(u) 대신 다른 kernel function 을 쓸 수도 있다. 보통 Gaussian kernel 을 많이 쓴다. 그럴 경우 p(x) 는 

$$p(x) = \frac{1}{N} \sum_{n=1}^N \frac{1}{(2\pi h^2)^{D/2}} \exp \{ -\frac{\left\vert x-x_n \right\vert^2}{2h^2} \}$$

kernel function 의 조건은 $k(u) \ge 0,\ \int k(u)du = 1$ 이면 된다.

### 5.2.2 Nearest-neighbor methods

kernel density estimators 의 문제는 데이터의 밀도가 높은 곳이나 작은 곳이나 같은 h를 쓴다는 점이다. 데이터의 밀도가 높은곳에서는 지나치게 over-smoothing 되고, 밀도가 낮은 곳에서는 noise 가 심한 결과가 나올 것이다. 그래서 h를 데이터 공간에 종속적이게 한 방법이 나왔고, 그게 knn 이다.

kernel density estimator 에서는 고정된 V를 쓰고 K값을 구했지만 knn 에서는 고정된 K 를 쓰고 V를 구해 p(x) 를 알아낸다. 이를 위해 x 주변의 작은 hypersphere 를 사용한다. 

kNN 은 classification 에 사용 할 수 있다. 이는 다들 알고있을 것이므로 생략한다.



# Proof

1. Antisym 이 mahalanobis 에서 사라진다

antisym 이면 

$$(A^{-1})^T = -A^{-1}$$

then

$$d = (x-\mu)^T A^{-1} (x-\mu)$$
$$d = d^T = (x-\mu)^T (A^{-1})^T (x-\mu)$$

양변을 더하면

$$2d = 0$$

$$\therefore d = 0$$

2. $A^{-1}$가 sym 이면 $A$ 또한 sym

간단하므로 생략

3. $A$ 가 real symmetric matrix 면 eigenvalue 도 real 이다

$$Av = \lambda v$$

양번에 conjugate 이용하면

$$\bar{Av} = \bar{\lambda v}$$

A가 real matrix 므로

$$A \bar{v} = \bar{\lambda v}$$

한편

$$\bar{v}^T A v = \bar{v}^T (A v) = \bar{v}^T \lambda v = \lambda \bar{v}^T v$$

$$= \bar{v}^T A^T v = (A \bar{v})^T  v = (\bar{\lambda v})^T v = \bar{\lambda} \bar{v}^T v$$

따라서 

$$\lambda = \bar{\lambda}$$

$$\therefore \lambda \in \mathbb{R}$$

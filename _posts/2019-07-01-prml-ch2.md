---
layout: post
title: "PRML Ch.2 - probability distribution"
categories: PRML
author: lee gunjun
---

density estimation: observed set $x_1, \cdots, x_n$ 이 주어졌을 때 $p(x)$ 을 모델링 하는 것.

conjugate prior probability, exponential family 

$D = {x_1, \cdots, x_N}$ 이라 하자.

Bernoulli: $Bern(x \vert \mu) = \mu^x(1-\mu)^{1-x} \text{, x}\in\{0,1\}$  

$\log p(D \vert \mu) = \sum_{n=1}^N \{x_n \log \mu + (1-x_n) \log (1-\mu) \}$  

$\mu^{MLE} = \frac{1}{N} \sum_{n=1}^N x_n$  

Binomial: $Bin(m \vert N, \mu) = \binom{N}{m}\mu^m(1-\mu)^{N-m}$

Bernoulli 와 Binomial 의 문제점: N=3 밖에 안되고 모두 x=0 이었다고 하자. 이 때 MLE 을 쓰면 미래에도 계속 0 이 나올것이라 생각함. 즉 쉽게 overfitting 된다. bayesian 처럼 해보기 위해 $\mu$의 사전분포를 도입해보자.

Beta: $Beta(\mu \vert a, b) = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\mu^{a-1}(1-\mu)^{b-1}$

$\mu$ 의 prior 를 beta 라 하고 bernoulli 의 likelihood 와 곱하면  
$p(\mu \vert m, N, a, b) \propto p(D \vert \mu) p(\mu) \propto \mu^{m+a-1} (1-\mu)^{N-m+b-1}$  
$\therefore p(\mu \vert m, l, a, b) \sim Beta(\mu \vert m+a, l+b),\ l=N-m$  
prior 를 beta 로 잡아서 posterior 를 계산했는데 이 또한 beta 가 됐다. 이러한 성질을 conjugacy 라 한다.

위와 같은 상황처럼 사전 분포를 잘 모델링 하면 매 관찰마다 얻어낸 사후 분포를 그 다음 관찰에 대해 사전분포로 사용할 수 있다. 이렇게 매번 업데이트 하는 것이 bayesian 적 관점에서 자연스럽다. 이는 사전 분포나 가능도 함수의 선택과는 관련없이 데이터가 iid 이면 된다.  

더 많은 데이터를 관측할수록 posterior 의 불확실성 정도가 줄어들까? 즉 다시말해 posterior 의 분산이 줄어들까?

$$\begin{matrix}
var_D\left[\mathbb{E}_\theta \left[ \theta \vert D \right] \right] &=& \mathbb{E}_D \left[\mathbb{E}_\theta\left[\theta \vert D\right]^2\right] - \mathbb{E}_D \left[\mathbb{E}_\theta\left[\theta \vert D\right]\right]^2\\
&=&\mathbb{E}_D \left[\mathbb{E}_\theta\left[\theta \vert D\right]^2\right] - \mathbb{E}_\theta\left[\theta\right]^2\\
&=&\mathbb{E}_D \left[\mathbb{E}_\theta\left[\theta \vert D\right]^2\right] + var_\theta\left[\theta\right] -\mathbb{E}_\theta\left[\theta^2\right]\\
&=&\mathbb{E}_D \left[\mathbb{E}_\theta\left[\theta \vert D\right]^2\right] + var_\theta\left[\theta\right] -\mathbb{E}_D\left[\mathbb{E}_\theta\left[\theta^2 \vert D\right]\right]\\
&=& -\mathbb{E}_D\left[var_\theta\left[\theta \vert D\right]\right] + var_\theta\left[\theta\right]
\end{matrix}$$

사후 평균의 분산은 사전 분산 - 사후 분산의 평균으로 나타내어진다. 즉 분산이 줄어든다! 물론 여기서 본건 사후 *평균*의 분산이므로 어쩔땐 커지기도 한다.

지금까지 binomial 의 사전분포로 beta 를 쓰는 걸 했다.  
multinomial 의 경우는 사전분포로 어떤 걸 써야할까?  
아마 자연스럽게 dirichlet 을 써야한다고 생각할 것이다. 그리고 그게 정답이다.

multinomial: $Mult(m_1, \cdots, m_K \vert \mu, N) = \binom{N}{m_1 \cdots m_K}\prod_{k=1}^K\mu_k^{m_n}$, $\sum_{k=1}^K m_k=N$

likelihood: $p(D \vert \mu) = \prod_{n=1}^N \prod_{k=1}^K \mu_k^{x_{nk}} = \prod_{k=1}^K \mu_k^{\sum_n x_{nk}} = \prod_{k=1}^K \mu_k^{m_k}$

사전분포로 다음과 같이 잡고 싶을 것이다.  
$p(\mu \vert \alpha) \propto \prod_{k=1}^K \mu_k^{\alpha_k - 1}$  
normalize 하면  
dirichlet: $Dir(\mu \vert \alpha) = \frac{\Gamma(\alpha_0)}{\Gamma(\alpha_1) \cdots \Gamma(\alpha_K)} \prod_{k=1}^K \mu_k^{\alpha_k - 1}$, $\alpha_0 = \sum_{k=1}^K \alpha_k$

dirichlet 을 prior 로 쓰고, likelihood 를 곱하면 사후분포가 다음과 같이 구해진다.  
$p(\mu \vert D, \alpha) \propto p(D \vert \mu) p(\mu \vert \alpha) \propto \prod_{k=1}^K \mu_k^{\alpha_k + m_k - 1}$  
우리가 원하는 대로 사후 분포 또한 dirichlet 을 따른다. normalize 하면 다음과 같은 식이 얻어진다.  
$p(\mu \vert D, \alpha) = Dir(\mu \vert \alpha+m)$

지금까진 discrete 변수를 모델링하는 분포였다.  
연속 변수를 모델링 해보자

Gaussian: $\mathcal{N}(x \vert \mu, \sigma^2) = \frac{1}{(2 \pi \sigma^2)^{1/2}}\exp\{- \frac{1}{2\sigma^2}(x-\mu)^2\}$  
D-dim Gaussian: $\mathcal{N}(x \vert \mu, \Sigma) = \frac{1}{(2\pi)^{D/2} \left\vert \Sigma \right\vert^{1/2}} \exp\{-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)\}$

참고로 gaussian 은 중요한 해석적 성질을 많이 가졌다.  
첫째로 Mahalanobis distance $\Delta^2 = (x-\mu)^T \Sigma^{-1} (x-\mu)$  
$\Sigma^{-1}={\Sigma^{-1}}^{sym} + {\Sigma^{-1}}^{antisym}$로 나누면 Mahaloanobis distance 에서 ${\Sigma^{-1}}^{antisym}$ 은 사라지므로 generality 을 잃지 않고 우리는 $\Sigma^{-1}$ 가 대칭행렬이라 할 수 있고 따라서 $\Sigma$ 또한 대칭행렬이다.

실수 대칭 행렬이므로 고유값 또한 실수다. 정규 직교 집합을 이루는 고유 벡터($u_i^Tu_j=I_{ij}$)를 선택하면 $\Sigma = \sum_{i=1}^D \lambda_i u_i u_u^T$ 가 될것이고 $\Sigma^{-1} = \sum_{i=1}^D \frac{1}{\lambda_i}u_iu_i^T$ 이다. 이를 mahalanobis distance 에 적용하면 $\Delta^2 = \sum_{i=1}^D \frac{y_i^2}{\lambda_i},\ y_i = u_i^T (x-\mu)$가 된다. 즉 새로운 좌표 $Y=U(x-\mu)$ 가 나오고, 여기서 일정 비례씩 곱한다음 거리를 재는 것.  
식으로 보면 이해가 잘 안되지만 그림(Figure 2.7) 보면 쉽다. 다시 한번 정리하면 mahalanobis distance 는 우리가 잘 알고 있는 직교 좌표로 먼저 점들을 옮겨준 다음, 각 방향으로 일정 비례씩 곱해준 거리다.

$\mathbb{E}[xx^T] = \mu\mu^T+\Sigma,\ cov[x]=\Sigma$

gaussian은 unimodal 이다. multimodal 은 못함.

conditional gaussian과 marginal gaussian도 gaussian 분포일까?  
답은 "그렇다"이다.  
아래 관련 내용을 적어놨는데 굳이 안봐도 된다.

conditional gaussian

$x \sim \mathcal{N}(x \vert \mu, \Sigma)$ 이고 $x = \binom{x_a}{x_b}$ 이며 그 평균값이 $\mu=\binom{\mu_a}{\mu_b}$ 라 하자. 공분산 행렬 $\Sigma=\begin{pmatrix}\Sigma_{aa} & \Sigma_{ab} \\ \Sigma_{ba} & \Sigma_{bb} \end{pmatrix}$ 가 되고, 공분산행렬은 대칭이라 할 수 있으므로 $\Sigma_{aa}$와 $\Sigma_{bb}$는 대칭행렬이고 $\Sigma_{ba}^T = \Sigma_{ab}$ 이다. 흔히 $\Sigma^{-1}=\Lambda$ 로 쓰고 precision matrix 라 부른다. 이 또한 대칭행렬이므로 $\Lambda=\begin{pmatrix}\Lambda_{aa} & \Lambda_{ab} \\ \Lambda_{ba} & \Lambda_{bb} \end{pmatrix}$ 이면 $\Lambda_{aa}$와 $\Lambda_{bb}$는 대칭행렬이고 $\Lambda_{ba}^T = \Lambda_{ab}$ 이다. 주의해야 할 점은 $\Sigma_{aa}^{-1}=\Lambda_{aa}$ 와 같은 건 아니라는 것.

잘 계산해보면 $\Sigma_{a \vert b}=\Lambda_{aa}^{-1},\ \mu_{a \vert b} = \mu_a - \Lambda_{aa}^{-1} \Lambda_{ab} (x_b - \mu_b)$ 를 얻음. 

marginal gaussian

$p(x_a) = \int p(x_a, x_b) dx_b$

$\mathbb{E}[x_a] = \mu_a$  
$cov[x_a] = \Sigma_{aa}$

위에 대한 그림은 그림2.9에 나와있다.

Gaussian 에서 MLE

$\log p(X \vert \mu, \Sigma) = - \frac{ND}{2}\log(2 \pi) - \frac{N}{2} \log \left\vert \Sigma \right\vert - \frac{1}{2} \sum_{n=1}^N(x_n - \mu)^T\Sigma^{-1}(x_n - \mu)$ 이고 미분해서 잘 구해보면

$\mu^{MLE} = \frac{1}{N}\sum_{n=1}^{N}x_n$, $\Sigma^{MLE} = \frac{1}{N}\sum_{n=1}^N (x_n - \mu^{MLE})(x_n - \mu^{MLE})^T$

그리고 이들의 expectation 을 구해보면 $\mathbb{E}[\mu^{MLE}] = \mu$, $\mathbb{E}[\Sigma^{MLE}] = \frac{N-1}{N}\Sigma$  
$\Sigma^{MLE}$ 는 biased estimator 다. $\tilde{\Sigma}^{MLE} = \frac{1}{N-1}\sum_{n=1}^N (x_n - \mu^{MLE})(x_n - \mu^{MLE})^T$ 로 unbiased estimator 로 바꿔서 쓸 수 있다.

Gaussian 에서 bayesian

x 가 Gaussian 확률 변수라 할때, $\mu$ 를 추정하는 문제를 풀어보자. $\sigma$ 는 알고있다고 가정

likelihood: $p(x \vert \mu) = \prod_{n=1}^N p(x_n \vert \mu) = \frac{1}{(2\pi\sigma^2)^{N/2}} \exp \{ -\frac{1}{2\sigma^2}\sum_{n=1}^N (x_n - \mu)^2 \}$

likelihood 가 이차식의 지수 형태므로 prior 로 gaussian 잡으면 posterior 도 gaussian 이 나올것이다.

prior 를 $p(\mu) = \mathcal{N} (\mu \vert \mu_0, \sigma^2_0)$ 라 하고 잘 계산하면

posterior: $p(\mu \vert x) = \mathcal{N} (\mu \vert \mu_N, \sigma^2_N)$, $\mu_N = \frac{\sigma^2}{N \sigma_0^2 + \sigma^2}\mu_0 + \frac{N \sigma^2_0}{N \sigma_0^2 + \sigma^2}\mu^{MLE}$, $\frac{1}{\sigma_N^2} = \frac{1}{\sigma_0^2}+\frac{N}{\sigma^2}$

반대로 x 가 Gaussian 확률 변수라 할때, $\sigma$ 를 추정하는 문제를 풀어보자. $\mu$ 는 알고있다고 가정

likelihood: $p(x \vert \lambda) = \prod_{n=1}^N p(x_n \vert \lambda) \sim \lambda^{N/2} \exp \{ -\frac{\lambda}{2}\sum_{n=1}^N (x_n - \mu)^2 \}$

이는 $\lambda$의 거듭제곱과 선형 지수함수를 곱한 형태이므로 prior 로 감마함수를 쓰면 될 것이다.

prior: $p(\lambda) \sim Gamma(\lambda \vert a_0, b_0) = \frac{1}{\Gamma(a_0)}{b_0}^{a_0} \lambda^{a_0-1} \exp (-b_0 \lambda)$

posterior: $p(\lambda \vert X) = \lambda^{a_0-1} \lambda^{N/2} \exp{-b_0\lambda - \frac{\lambda}{2}\sum_{n=1}^N (x_n - \mu)^2} \sim Gamma(\lambda \vert a_N, b_N)$

$a_N = a_0 + \frac{N}{2}, b_N = b_0 + \frac{1}{2} \sum_{n=1}^N (x_n - \mu)^2 = b_0 + \frac{N}{2} {\sigma^{MLE}}^2$

이제 평균과 분산 둘 다 모른다고 해보자.

likelihood: $p(X \vert \mu, \lambda) = \prod_{n=1}^N \left( \frac{\lambda}{2 \pi} \right)^{1/2} \exp \{ -\frac{\lambda}{2}(x_n - \mu)^2 \}$

prior 로 Gaussian Gamma 분포를 쓰면 된다. 복잡하니 생략함. 다변량에서는 Wishart 분포를 사용함.

----

student-t 분포를 배워보자.

Gaussian 의 conjugate 가 Gamma 인걸 확인했다. x에 대한 marginal 을 구해보면

$p(x \vert \mu, a, b) = \int_0^{\infty} \mathcal{N}(x \vert \mu, \tau^{-1})Gamma(\tau \vert a, b) d\tau = \frac{\Gamma(b/2 + 1/2)}{\Gamma(b/2)}\left( \frac{a}{\pi b} \right)^{1/2} \left[ 1+\frac{a(x-\mu)^2}{b} \right]^{-b/2-1/2}$ 가 되고 이게 student-t 분포다.

t 분포는 outlier 에 robust 하다. 그림 2.16 참고

----

Gaussian 을 혼합하면 mixture of gaussians 이 된다. $p(x) = \sum_{k=1}^K \pi_k \mathcal{N}(x \vert \mu_k, \Sigma_k)$ 당연히 $\sum \pi_k = 1$

여기서 $\pi$ 를 $\pi_k = p(k)$ 즉 k 번째 성분을 뽑을 확률로 보면 $p(x) = \sum p(k) p(x\vert k)$ 가 됨. "가우시안들 중에서 하나를 고를 확률 * 그 가우시안에서 x가 나올 확률" 들의 합이 되고, $p(x \vert k)$ 를 responsibilities 라 한다.

log likelihood: $\log p(X \vert \pi, \mu, \Sigma) = \sum_{n=1}^N \log{\sum_{k=1}^K \pi_k \mathcal{N}(x_n \vert \mu_k, \Sigma_k)}$

이제는 mle 를 이전에 했던 것처럼 쉽게 구할 수 없다. 구하는 방법으론 numerical optimization 혹은 EM(expectation maximum) 이 있다. EM은 9장에서 열심히 배울 것이다. numerical optimization 은 안 배운다. 즉 우린 최소 9장까진 할수있는게 없다. -끝-

----

exponential family 에 대해 알아보자.

2장에서 지금까지 본 모든 분포는 (mixture of gaussians 빼고) 모두 exponential family 에 속한다.
 
exponential family 는 $p(x \vert \eta) = h(x)g(\eta)\exp{\eta^T u(x)}$ 처럼 되는 것

각 분포들을 저 형태로 만들어보는 연습을 해보자.

*Bernoulli*

$Bern(x \vert \mu) = \mu^x (1-\mu)^{1-x} = (1-\mu) \exp\{ \log(\frac{\mu}{1-\mu})x \}$

여기서 $\eta = \log(\frac{\mu}{1-\mu})$ 인데 이를 $\mu$ 로 정리하면

$\mu = \sigma(\mu) = \frac{1}{1+\exp(-\eta)}$ : sigmoid

*Multinoulli*

$Multi(x \vert \mu) = \prod_{k=1}^K \mu_k^{x_k} = \exp \{ \sum x_k \log \mu_k \}$

여기서 $\eta_k = \log \mu_k$ 이고, 정리하면 $\mu_k = \frac{\exp(\eta_k)}{1+\sum \exp(\eta_j)}$ : softmax

*gaussian*

별 거 없으니 생략

sufficient statistic: mle 의 estimate 계산에 쓰이는 statistic. 얘들만 가지고 있으면 mle 를 할 수 있다. 예를 들어 Bernoulli 의 mle 에는 $\mu^{MLE} = \frac{1}{N} \sum_i x_i$. 즉 x의 각 값을 저장할 필요 없이 누적들만 저장하고 있으면 된다. 따라서 sufficient statistic 은 $\sum_i x_i$ 이다.

----

noninformative prior

prior 에서 어떤 점이 p(x) = 0 이면 사후 분포에서도 p(x) = 0 이 된다. 사전분포에 대해 아무런 정보가 없는데 저런 prior 를 사용했다간 잘못된 결과가 나오기 쉽다. 사전분포에 대한 아무런 정보가 없으면 어떡할까? discrete 변수의 경우 1/k 로 주는 방법이 있다. 

----

non-parametric method

parameter 가 없는 밀도추정방법이다.

*histogram method*

$p_i = \frac{n_i}{N \Delta_i}$

*kernel density estimators*

구역 $\mathcal{R}$ 에서 probability mass 를 구해보면 $P = \int_\mathcal{R} p(x)dx$ 이다. V 를 R의 부피라 하자. 그리고 문제 정의를 input x가 R에 속하냐 속하지 않냐의 문제로 보면 binomial 이 되고, N번 뽑아서 K 번 뽑혔다고 하면 $p(x) = \frac{K}{NV}$ 가 된다.

이를 바탕으로 KNN 나옴. 그리고 V 고정하고 K를 구하는 kernel density estimator 도 나온다.

먼저 kernel density estimator 에 대해 알아보자.

우리가 확률밀도 p(x)를 구하고 싶은 x가 있고, x 주변의 작은 hypercube R 이 있다. 다음과 같은 함수를 이용하여 구역 R에 속하는 points 의 수 K 를 세자 

$$k(u) = \begin{cases} 1 & \vert u_i \vert \le 1/2, i=1,\cdots,D \\ 0 & otherwise \end{cases}$$

k(u) 는 kernel function 중 하나이다. k(u) 를 이용하면 x 를 중심으로 한변의 길이가 h 인 cube 안에 point y 가 들어가는 경우를 k((x-y)/h) 로 쓸 수 있다.

즉 $K = \sum_{n=1}^N k(\frac{x-x_n}{h})$

$\therefore p(x) = \frac{1}{N} \sum_{n=1}^N \frac{1}{h^D} k(\frac{x-x_n}{h})$

다른 kernel function 을 쓸 수도 있다. 보통 Gaussian kernel 을 많이 쓴다. 그럴 경우 p(x) 는 

$$p(x) = \frac{1}{N} \sum_{n=1}^N \frac{1}{(2\pi h^2)^{D/2}} \exp \{ -\frac{\left\vert x-x_n \right\vert^2}{2h^2} \}$$

kernel function 의 조건은 $k(u) \ge 0,\ \int k(u)du = 1$ 이면 된다.

*knn*

kernel density estimators 의 문제는 데이터의 밀도가 높은 곳이나 작은 곳이나 같은 h를 쓴다는 점이다. 데이터의 밀도가 높은곳에서는 지나치게 over-smoothing 되고, 밀도가 낮은 곳에서는 noise 가 심한 결과가 나올 것이다. 그래서 h를 데이터 공간에 종속적이게 한 방법이 나왔고, 그게 knn 이다.

kernel density estimator 에서는 고정된 V를 쓰고 K값을 구했지만 knn 에서는 고정된 K 를 쓰고 V를 구해 p(x) 를 알아낸다. 이를 위해 x 주변의 작은 hypersphere 를 사용한다. 다음 설명은 다들 알고있으므로 생략.